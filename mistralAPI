import librosa
import librosa.display
import matplotlib.pyplot as plt
import requests
import numpy as np
api_key = "R3gzwc9LrUWCLyetZnT5puBhreLVaMrF"
def load_audio_file(file_path):
    signal, sample_rate = librosa.load(file_path)
    return signal, sample_rate

def plot_spectrogram(signal, sample_rate):
    plt.figure(figsize=(10, 4))
    spectrogram = librosa.feature.melspectrogram(y=signal, sr=sample_rate)
    librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max), 
    sr=sample_rate, x_axis='time', y_axis='mel')
    plt.colorbar(format='%+2.0f dB')
    plt.title('Spectrogram')
    plt.tight_layout()
    plt.show()

def ask_mistral(question):
    url = "https://api.mistral.ai/v1/chat/completions"  
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    body = {
        "model": "mistral-small",
        "messages": [{"role": "user", "content": question}]
    }

    response = requests.post(url, headers=headers, json=body)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return "Mistral request failed."


file_path = input("Enter the path to your audio file (e.g., a Fairuz clip): ").strip()
signal, sample_rate = load_audio_file(file_path)
plot_spectrogram(signal, sample_rate)

question = "Explain what a spectrogram shows using Fairuz's voice as an example."
explanation = ask_mistral(question)  

print("\nMistral's Explanation:")
print(explanation)
